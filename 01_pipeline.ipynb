{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e337b23-86f2-4f4b-81f0-c4eb2c4e37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"py\", \"-m\", \"uv\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8facc568-0e4b-48b8-af75-73cfa9a826c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as spark_func\n",
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder, MinMaxScaler\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "from uuid import uuid4\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04cecaa-0a5d-4e38-bd24-301841cc2f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5670d9-447c-4e57-9f92-c56862fea9d7",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc86bde-5fdd-4c5e-9cd5-4bb435d39916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark():\n",
    "    print(\"Creating spark session with custom temp dir\")\n",
    "    dirname = str(uuid4())\n",
    "    os.mkdir(f\"spark_dir/{dirname}\")\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"Preprocessing\").getOrCreate()\n",
    "    spark.conf.set(\"spark.local.dir\", f\"/spark_dir/{dirname}\")\n",
    "    return spark, dirname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56975b-5cea-4986-a4ca-69745467bae6",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224f364-d06a-44a8-a13e-87e7a618a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframes(\n",
    "    fraud_ratio: float,\n",
    "    test_limit: int\n",
    "):\n",
    "    print(\"Loading dataframes\")\n",
    "    train_fraud = (\n",
    "        spark\n",
    "        .read.option(\"header\", True)\n",
    "        .csv(\"resources/fraudTrain.csv\")\n",
    "        .filter(\"is_fraud = 1\")\n",
    "    )\n",
    "    non_fraud_records = int(train_fraud.count() / fraud_ratio) - train_fraud.count()\n",
    "    train_df = train_fraud.union(\n",
    "        (\n",
    "            spark\n",
    "            .read.option(\"header\", True)\n",
    "            .csv(\"resources/fraudTrain.csv\")\n",
    "            .filter(\"is_fraud = 0\")\n",
    "            .orderBy(spark_func.rand())\n",
    "            .limit(non_fraud_records)\n",
    "        )\n",
    "    )\n",
    "    fraud = train_df.where(spark_func.col(\"is_fraud\") == \"1\").count()\n",
    "    non_fraud = train_df.where(spark_func.col(\"is_fraud\") == \"0\").count()\n",
    "    \n",
    "    print(f\"Train fraud records = {fraud}\\nNon fraud records {non_fraud}\\nFraud ratio {round(fraud / (fraud + non_fraud), 4)}\")\n",
    "    \n",
    "    test_df = spark.read.option(\"header\", True).csv(\"resources/fraudTest.csv\").orderBy(spark_func.rand()).limit(test_limit)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a44716e-be42-44fc-a8b4-0d18975c5fd6",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34a22c-d11f-499f-b6b5-078aa74e4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelTransformer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    def _transform(self, dataframe):\n",
    "        return (\n",
    "            dataframe\n",
    "            .withColumn(\"is_fraud\", spark_func.col(\"is_fraud\").cast(\"int\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d516582-5204-4b8b-bb9f-050bd3c0a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatetimeTransformer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    def _transform(self, dataframe):\n",
    "        dataframe = (\n",
    "            dataframe\n",
    "            .withColumn(\n",
    "                \"date\",\n",
    "                spark_func.to_date(dataframe[\"trans_date_trans_time\"], \"yyyy-MM-dd HH:mm:ss\")\n",
    "            ) \n",
    "            .withColumn(\n",
    "                \"date_time\",\n",
    "                spark_func.to_timestamp(dataframe[\"trans_date_trans_time\"], \"yyyy-MM-dd HH:mm:ss\")\n",
    "            )\n",
    "        )\n",
    "        return (\n",
    "            dataframe\n",
    "            .withColumn(\"year\", spark_func.year(dataframe[\"date\"]))\n",
    "            .withColumn(\"month\", spark_func.month(dataframe[\"date\"]))\n",
    "            .withColumn(\"day\", spark_func.day(dataframe[\"date\"]))\n",
    "            .withColumn(\"hour\", spark_func.hour(dataframe[\"date_time\"]))\n",
    "            .withColumn(\"minute\", spark_func.minute(dataframe[\"date_time\"]))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e86dc-e0f1-4c99-b1d7-16ef21ef52fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionsTransformer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    _power = 0.25\n",
    "    _cat_diff_columns = [\"merchant\", \"category\", \"gender\", \"state\", \"city\"]\n",
    "    \n",
    "    def _transform(self, dataframe):\n",
    "        dataframe = dataframe.withColumn(\"amt\", spark_func.col(\"amt\").cast(\"float\"))\n",
    "        dataframe = dataframe.withColumn(\"amt\", spark_func.power(spark_func.col(\"amt\"), self._power))\n",
    "\n",
    "        for col in self._cat_diff_columns:\n",
    "            dataframe = dataframe.join(\n",
    "                dataframe.groupBy(\"merchant\").agg(spark_func.mean(\"amt\").alias(f\"mean_{col}_amt\")), \n",
    "                on=\"merchant\", \n",
    "                how=\"right\"\n",
    "            )\n",
    "            dataframe = dataframe.withColumn(f\"amt_{col}_diff\", spark_func.col(\"amt\") - spark_func.col(f\"mean_{col}_amt\"))\n",
    "\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19f158-ef11-4daf-9445-78447d551248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MerchantTransformer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    _lvl0_values = json.load(open(\"resources/lvl0_merchants.json\", \"r\"))\n",
    "    _lvl1_values = json.load(open(\"resources/lvl1_merchants.json\", \"r\"))\n",
    "    _lvl2_values = json.load(open(\"resources/lvl2_merchants.json\", \"r\"))\n",
    "    _sig_categories = json.load(open(\"resources/sig_categories.json\", \"r\"))\n",
    "    \n",
    "    def _transform(self, dataframe):\n",
    "        dataframe = self._merchant_levels(dataframe)\n",
    "        dataframe = self._merchant_history(dataframe)\n",
    "        dataframe = self._category_levels(dataframe)\n",
    "        dataframe = self._categories_history(dataframe)\n",
    "        return dataframe\n",
    "\n",
    "    def _merchant_levels(self, dataframe):\n",
    "        return (\n",
    "            dataframe\n",
    "            .withColumn(\"merchant_lvl_0\", spark_func.when(spark_func.col(\"merchant\").isin(self._lvl0_values), 1).otherwise(0))\n",
    "            .withColumn(\"merchant_lvl_1\", spark_func.when(spark_func.col(\"merchant\").isin(self._lvl1_values), 1).otherwise(0))\n",
    "            .withColumn(\"merchant_lvl_2\", spark_func.when(spark_func.col(\"merchant\").isin(self._lvl2_values), 1).otherwise(0))\n",
    "        )\n",
    "\n",
    "    def _merchant_history(self, dataframe):\n",
    "        return dataframe.join(\n",
    "            spark.read.option(\"header\", True).csv(\"resources/merchant_fraud_history.csv\"), \n",
    "            on=\"merchant\", \n",
    "            how=\"right\"\n",
    "        )\n",
    "\n",
    "    def _category_levels(self, dataframe):\n",
    "        return (\n",
    "            dataframe\n",
    "            .withColumn(\n",
    "                \"sig_categories\",\n",
    "                spark_func.when(spark_func.col(\"category\").isin(self._sig_categories), 1).otherwise(0))\n",
    "        )\n",
    "\n",
    "    def _categories_history(self, dataframe):    \n",
    "        return dataframe.join(\n",
    "            spark.read.option(\"header\", True).csv(\"resources/categories_fraud_history.csv\"), \n",
    "            on=\"category\", \n",
    "            how=\"right\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7c536-f794-4fd8-bf3e-68015365461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityPopulationTransformer(Transformer, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    _power = 0.25\n",
    "    \n",
    "    def _transform(self, dataframe):\n",
    "        dataframe = dataframe.withColumn(\"city_pop\", spark_func.col(\"city_pop\").cast(\"float\"))\n",
    "        dataframe = dataframe.withColumn(\"city_pop\", spark_func.power(spark_func.col(\"city_pop\"), self._power))\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2998eb-ba1d-4d2d-9ba1-8b099b4b82e5",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1286b-a7a8-4a3d-9398-e0bb70e7f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_cols = [\n",
    "    \"amt\",\n",
    "    \"trans_date_trans_time\",\n",
    "    \"merchant\",\n",
    "    \"category\",\n",
    "    \"gender\", \n",
    "    \"state\", \n",
    "    \"city\",\n",
    "    \"city_pop\",\n",
    "    \"is_fraud\"\n",
    "]\n",
    "\n",
    "final_cols = [\n",
    "    \"amt\",\n",
    "    \"amt_merchant_diff\",\n",
    "    \"amt_category_diff\",\n",
    "    \"amt_gender_diff\",\n",
    "    \"amt_state_diff\",\n",
    "    \"amt_city_diff\",\n",
    "    \n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"hour\", \n",
    "    \"minute\",\n",
    "\n",
    "    \"category_dummy\",\n",
    "    \"gender_dummy\"\n",
    "]\n",
    "\n",
    "label = \"is_fraud\"\n",
    "\n",
    "evaluation_cols = [\n",
    "    \"is_fraud\", \n",
    "    \"rawPrediction\", \n",
    "    \"probability\", \n",
    "    \"prediction\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba94dbc-4983-401c-b5fe-d5d07a530d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(model_stage):\n",
    "    return Pipeline(\n",
    "        stages=[       \n",
    "            # custom\n",
    "            LabelTransformer(),\n",
    "            DatetimeTransformer(),\n",
    "            TransactionsTransformer(),\n",
    "            MerchantTransformer(),\n",
    "            CityPopulationTransformer(),\n",
    "    \n",
    "            # category one hot\n",
    "            StringIndexer(inputCol=\"category\", outputCol=\"category_index\"),\n",
    "            OneHotEncoder(inputCol=\"category_index\", outputCol=\"category_dummy\"),\n",
    "    \n",
    "            # gender one hot\n",
    "            StringIndexer(inputCol=\"gender\", outputCol=\"gender_index\"),\n",
    "            OneHotEncoder(inputCol=\"gender_index\", outputCol=\"gender_dummy\"),\n",
    "    \n",
    "            # min max scaler\n",
    "            VectorAssembler(inputCols=final_cols, outputCol=\"features\"),\n",
    "            MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\"),\n",
    "\n",
    "            # ml model\n",
    "            model_stage\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebc2e2e-8828-4599-946e-51fb58ecdbf4",
   "metadata": {},
   "source": [
    "# ML experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a19695-b726-42ef-b2f8-ea6caad93ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_reps = 2\n",
    "fraud_ratio = 0.5\n",
    "test_sample = 10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97cd27-6553-44bf-b4c9-c3848e214784",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:///tmp/mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967ab40-e00e-4133-96c4-4dc8f2fe7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(featuresCol=\"features\", labelCol=label)\n",
    "models = [\n",
    "    [\n",
    "        LogisticRegression, \n",
    "        \"LogisticRegression\"\n",
    "    ],\n",
    "    [\n",
    "        RandomForestClassifier, \n",
    "        \"RandomForest\"\n",
    "    ],\n",
    "    [\n",
    "        GBTClassifier, \n",
    "        \"GBT\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace634b0-9971-46fd-b2e4-0e767103e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    for i in range(cross_val_reps):\n",
    "        spark, dirname = get_spark()\n",
    "        try:\n",
    "            train_df, test_df = get_dataframes(fraud_ratio, test_sample)\n",
    "            evaluator = BinaryClassificationEvaluator(labelCol=label, metricName=\"areaUnderPR\")\n",
    "            with mlflow.start_run():\n",
    "                print(f\"Working on: {model[1]} ({i})\")\n",
    "                pipe = get_pipeline(model[0](**model_kwargs))\n",
    "                pipe_model = pipe.fit(train_df.select(*origin_cols))\n",
    "                predictions_train = pipe_model.transform(train_df.select(*origin_cols)).select(*evaluation_cols)\n",
    "                predictions_test = pipe_model.transform(test_df.select(*origin_cols)).select(*evaluation_cols)\n",
    "            \n",
    "                auc_train = evaluator.evaluate(predictions_train)\n",
    "                auc_test = evaluator.evaluate(predictions_test)\n",
    "            \n",
    "                mlflow.log_param(\"model\", f\"{model[1]}_{i}\")\n",
    "                mlflow.log_metric(\"train_auc_pr\", auc_train)\n",
    "                mlflow.log_metric(\"test_auc_pr\", auc_test)\n",
    "    \n",
    "                spark.stop()\n",
    "        except Exception as e:\n",
    "            spark.stop()\n",
    "            raise e\n",
    "        finally:\n",
    "            shutil.rmtree(f\"spark_dir/{dirname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7259f-a316-4d6d-ae67-25f8c007d351",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b3549-9350-4efe-9f5a-a9f28fb3a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = mlflow.search_runs(experiment_ids=[\"0\"])\n",
    "runs_df[\"params.model_family\"] = runs_df[\"params.model\"].apply(lambda x: x.split(\"_\")[0] if x else x)\n",
    "runs_df = (\n",
    "    runs_df\n",
    "    [runs_df.status == \"FINISHED\"]\n",
    "    [:cross_val_reps*len(models)]\n",
    "    .groupby(\"params.model_family\")\n",
    "    .agg({\n",
    "        \"metrics.test_auc_pr\": \"mean\",\n",
    "        \"metrics.train_auc_pr\": \"mean\",\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35b8ac-56d9-493d-85f3-2b9db41eea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "x_data = runs_df[\"params.model_family\"].to_list()\n",
    "y_data = runs_df[\"metrics.train_auc_pr\"].to_list()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        name=\"Train\",\n",
    "        x=x_data,\n",
    "        y=y_data,\n",
    "        text=[round(y, 3) for y in y_data],\n",
    "        marker_color=\"teal\"\n",
    "    )\n",
    ")\n",
    "\n",
    "x_data = runs_df[\"params.model_family\"].to_list()\n",
    "y_data = runs_df[\"metrics.test_auc_pr\"].to_list()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        name=\"Test\",\n",
    "        x=x_data,\n",
    "        y=y_data,\n",
    "        text=[round(y, 3) for y in y_data],\n",
    "        marker_color=\"orange\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"<b>AUC PR values for tested models</b><br>Cross val reps = {cross_val_reps}\",\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    yaxis=dict(range=(0, 1.1))\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57295ed2-022b-49ae-a8e5-ba9486c389c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
